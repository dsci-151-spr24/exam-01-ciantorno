---
title: "Take Home Exam #1"
author: "Chiara Iantorno"
date: "February 24, 2024"
output: html_document
---

```{r}
#| label: setup
#| include: true

# set the echo option to FALSE to see how the document looks with the code suppressed
knitr::opts_chunk$set(echo = FALSE)
```

## Rules

1.  Your solutions must be written up in the R Markdown (Rmd) file called `exam-01.Rmd`.
    This file must include your code and write up for each task.
    Your "submission" will be whatever is in your exam repository at the deadline.
    Commit and push the Rmd and the md outputs of that file.

2.  This exam is open book, open internet, closed other people.
    You may use any online or book based resource you would like, but you must include citations for any code that you use (directly or indirectly).
    You **may not** consult with anyone else about this exam other than the Professor or TA for this course.
    You cannot ask direct questions on the internet, or consult with each other, not even for hypothetical questions.

3.  You have until **[DUE DATE]** to complete this exam and turn it in via your personal Github repo - late work will **not** be accepted.
    Technical difficulties are **not** an excuse for late work - do not wait until the last minute to knit / commit / push.

4.  Each question requires a (brief) narrative as well as a (brief) description of your approach.
    You can use comments in your code, but do not extensively count on these.
    I should be able to suppress **all** the code in your document and still be able to read and make sense of your answers.
    See the first setup code chunk in your Rmd file to experiment with suppressing and revealing your code.

5.  Even if the answer seems obvious from the R output, make sure to state it in your narrative as well.
    For example, if the question is asking what is 2 + 2, and you have the following in your document, you should additionally have a sentence that states "2 + 2 is 4."

``` r
2 + 2
# 4
```

1.  You may only use `tidyverse` and `nycflights13` (and its dependencies) for this assignment. Your solutions may not use any other R packages.

## Academic Integrity Statement

*I, Chiara Iantorno, hereby state that I have not communicated with or gained information in any way from my classmates or anyone other than the Professor or TA during this exam, and that all work is my own.*

**A note on sharing / reusing code:** I am well aware that a huge volume of code is available on the web to solve any number of problems.
For this exam you are allowed to make use of any online resources (e.g. StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration).
You are also not allowed to ask a question on an external forum, you can only use answers to questions that have already been answered.
Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.
All communication with classmates is explicitly forbidden.

## Getting help

You are not allowed to post any questions on the public community repo or the public questions channel on Slack.
Any questions about the exam must be asked in person in office hours or on Slack via direct message to the Professor or the TAs.
For quickest response we recommend that you start a direct message with the Professor and all the TAs so that whoever gets to it first can respond to you.

## Grading and feedback

The total points for the questions add up to 90 points.
The remaining 10 points are allocated to code style, commit frequency and messages, overall organization, spelling, grammar, etc.
There is also an extra credit question that is worth 5 points.
You will receive feedback as an issue posted to your repository, and your grade will also be recorded on Sakai.

## Logistics

Answer the questions in the document called `exam-01.Rmd`.
Add your code and narrative in the spaces below each question.
Add code chunks as needed.
Use as many lines as you need, but keep your narrative concise.

Before completing, make sure to supress the code and look over your answers one more time.
If the narrative seems sparse or choppy, edit as needed.
Then, revert back to revealing your code.

Don't forget that you will need to configure your user name and email for Git to be able to push to your repository.

## Packages

In addition to `tidyverse`, you will need the `nycflights13` package for the data.
You will first need to install these packages and then load them.

## The data

The `nycflights13` package contains information about all flights that departed from NYC (e.g. EWR, JFK and LGA) in 2013.
The main data is in the `flights` data frame, but there are additional data sets which may help understand what causes delays, specifically:

-   `weather`: hourly meteorological data for each airport
-   `planes`: construction information about each plane
-   `airports`: airport names and locations
-   `airlines`: translation between two letter carrier codes and names

## Questions

1.  **Question 1 (10 points)** - What are the ten most common destinations for flights from NYC airports in 2013?
    Make a table that lists these in descending order of frequency and shows the number of fligts heading to each airport.
    
```{r}
library(magrittr)
library(dplyr)

nycflights13::flights %>% 
  count(dest) %>% 
  arrange(desc(n)) 
```



**The ten most common destinations are Chicago (ORD), Atlanta (ATL), Los Angeles (LAX), Boston (BOS), Orlando (MCO), Charlotte (CLT), San Francisco (SFO), Fort Lauderdale (FLL), Miami (MIA), and Washington D.C. (DCA).  I used the count function to create the frequency table and then I looked at my data to see which column name signifies destination.  I then saw that it was "dest" that signified destination and then I added 'arrange(desc(n)) to make sure that the destinations were sorted in descending order.** 



2.  **Question 2 (10 points)** - Which airlines have the most flights departing from NYC airports in 2013?
    Make a table that lists these in descending order of frequency and shows the number of flights for each airline.
    In your narrative mention the names of the airlines as well.
    *Hint:* You can use the `airlines` dataset to look up the airline name based on `carrier` code.
    
```{r}
library(nycflights13)

flights %>%
  count(carrier) %>% 
  arrange(desc(n)) %>% 
  inner_join(airlines) 
```

**The airlines with the most flights departing from NYC airports in 2013 are United Airlines, JetBlue Airways, ExpressJet Airlines, Delta Air Lines, and American Airlines.  I used the `count` function to count the carriers in the table, the arrange(desc(n)) function to arrange the flights and airlines in descending order, and the `inner_join(airlines)` function to combine the `flights` and `airlines` datasets.**

3.  **Question 3 (10 points)** - Consider only flights that have non-missing arrival delay information.
    Your answer should include the name of the carrier in addition to the carrier code and the values asked.
    
```{r}
flights %>%
  group_by(carrier) %>% 
  summarise(delay = mean(arr_delay, na.rm = TRUE)) %>% 
  inner_join(airlines) %>% 
  arrange(desc(delay)) 
  
```


    a\.
    Which carrier had the highest mean arrival delay?
    
**The F9 carrier from Frontier Airlines had the highest mean arrival delay.**

    b\.
    Which carrier had the lowest mean arrival delay?
    
**The AS carrier from Alaska Airlines had the lowest mean arrival delay.**

**I used the `group_by` function to make sure that the table was grouped by carrier, the `summarise` function to put multiple values into one, `na.rm` to limit the table to non-missing values, and `inner_join` and `arrange` to combine datasets and list the variables in descending order for organizational purposes.**

4.  **Question 4 (10 points)** - What was the mean temperature at the origin airport on the day with the highest departure delay?
    Your answer should include the name of origin airport, the date with the highest departure delay, and the mean temperature on that day.
  
```{r}
flights %>%
  arrange(desc(dep_delay)) %>%
  select(dep_delay, month, day, origin) %>%
  slice(1)
```

```{r}
weather %>%
  filter(month == 1, day == 9, origin == "JFK") %>%
  summarise(mean_temp = mean(temp))
```
**The mean temperature at the origin airport on the day with the highest departure delay was 42.7 at JFK airport on month 1, day 9.  I created a table with arrange and select for the dataset `flights` to figure out the origin airport on the day with the highest departure delay and I created a table with filter and summarize to figure out the mean temperature for that origin airport.**

5.  **Question 5 (15 points)** - Consider breaking the day into four time intervals: 12:01am-6am, 6:01am-12pm, 12:01pm-6pm, 6:01pm-12am.


    a\.
    Calculate the proportion of flights that are delayed at departure at each of these time intervals.

```{r}
flights <- flights %>%
  mutate(time_of_day = case_when(
    dep_time >= 001  & dep_time <= 600  ~ "12:01am - 6am",
    dep_time >= 601  & dep_time <= 1200 ~ "6:01am - 12pm",
    dep_time >= 1201 & dep_time <= 1800 ~ "12:01pm - 6pm",
    dep_time >= 1801                    ~ "6:01pm - 12am"
  ))

flights %>%
  filter(!is.na(dep_delay)) %>%
  mutate(Dep_delay = ifelse(dep_delay > 0, "delayed", "ontime")) %>%
  count(time_of_day, Dep_delay) %>%
  group_by(time_of_day) %>%
  mutate(prop = n / sum(n)) %>%
  filter(Dep_delay == "delayed") %>%
  arrange(prop)
```
**I used `mutate` and separated the time intervals to make sure that the intervals would show up in the table and I used `filter` and `mutate` to make the variables "Dep-delay" and "prop".**
  
    b\.
    Comment on how the likelihood of being delayed change throughout the day?
    
**It is more likely that one's flight would be delayed from 6:01pm - 12am, since that interval seems to have the highest proportion of delayed flights.**
    

Citation/source for creating a variable in part a: Section 9.6 of chapter 9 in the Epidemiologist R Handbook (https://www.epirhandbook.com/en/new_pages/dates.html)

6.  **Question 6 (15 points)** - Find the flight with the longest air time.
```{r}
flights %>%
  arrange(desc(air_time)) %>%
  slice(1) %>%
  select(air_time, dest, tailnum) %>%
  inner_join(planes, "tailnum") %>%
  select(air_time, seats, tailnum, dest)
```
    a\.
    How long is this flight?

**This flight was 695 minutes long.**
   
    b\.
    What city did it fly to?

**The flight was to Honolulu.**

    c\.
    How many seats does the plane that flew this flight have?

**This flight has 292 seats.**

**I used `arrange(desc)` to make sure the flight with the longest airtime was at the top of the data and I used `slice` to narrow the data down to the top flight.  I used `inner_join` to join tailnum from `planes` data set to `flights` and to make sure that `seats` were joined as well.  I used `select` to select which rows I wanted in my table.**

7.  **Question 7 (15 pts)** - The `airports` data frame contains information on a large number of primarily American airports.
    These data include location information for these airports in the form of latitude and longitude coordinates.
    In this question we limit our focus to the [Contiguous United States](https://en.wikipedia.org/wiki/Contiguous_United_States).
    Visualize and describe the distribution of the longitudes of airports in the Contiguous United States.
    What does this tell you about the geographical distribution of these airports?
    *Hint:* You will first need to limit your analysis to the Contiguous United States.
    [This Wikipedia article](https://en.wikipedia.org/wiki/List_of_extreme_points_of_the_United_States) can help, but you're welcomed to use other resources as well.
    Make sure to cite whatever resource you use.
    
I used location information from the Wikipedia article, https://en.wikipedia.org/wiki/List_of_extreme_points_of_the_United_States, and I used https://latlongdata.com/lat-long-converter/ to convert the information into decimal degrees.

**The northernmost point of the contiguous United States is Northwest Angle inlet in Lake of the Woods, Minnesota, at 49°23′04.1″N 95°9′12.2″W, or 49.3844722222 and -95.1533888889.**

**The southernmost point of the contiguous United States is Western Dry Rocks in Florida Keys, Florida, at 24°26.8′N 81°55.6′W, or 24.4466666667 and -81.9266666667.**

**The easternmost point of the contiguous United States is Sail Rock in  Lubec, Maine 44°48′45.2″N 66°56′49.3″W, or 44.8125555556 and -66.9470277778.** 

**The westernmost point of the contiguous United States is Cape Alava, Washington, at 48°9′51″N 124°43′59″W, or 48.1641666667 and -124.7330555556.**

**With this information, I can make an `r` code chunk that filters only the contiguous United States.**

```{r}
library(ggplot2)

airports %>%
  filter(
    lat > 24.4466666667 & lat < 49.3844722222,
    lon > -124.7330555556 & lon < -66.9470277778) %>%

ggplot(aes(x = lon, y = lat)) +
  geom_point()
  
```

**This visualization shows me that the the distribution of airports is most dense around places on the East Coast, like New York and parts of New England, Florida, Tennessee.  There are also other places with clusters of airports, like Southern California, around Wisconsin, and the coast of Washington.  Airports are more spaced out throughout the other areas of the US.  I chose a scatterplot for this visualization, so that I could clearly see which places had more of a distribution of airports as opposed to other places.**

8.  **Question 8 (15 pts)** - Recreate the plot included below using the `flights` data.
    Once you have created the visualization, in no more than one paragraph, describe what you think the point of this visualization might be.
    *Hint:* The visualization uses the variable `arrival`, which is not included in the `flights` data frame.
    You will have to create `arrival` yourself, it is a categorical variable that is equal to `"ontime"` when `arr_delay <= 0` and `"delayed"` when `arr_delay > 0`.

```{r}
flights %>% 
  filter(dest %in% c("PHL","RDU")) %>% 
  filter(month==12) %>% 
  mutate(
    arrival= case_when(arr_delay <= 0 ~ "ontime", arr_delay > 0 ~ "delayed")) %>% 
  filter(!is.na(arrival)) %>% 
          ggplot(aes(x=arrival, y= dep_delay, color=dest))+
  geom_boxplot()+
  facet_grid(dest~origin)+
  
  labs(title="On time performance of NYC flights",
       subtitle="December 2013",
        x= "Arrival",
        y="Departure delay", 
        color = "Destination")
```

**I think that the point of this visualization is to show the relationship between on time and delayed flights in NYC airports going to Philadelphia and Raleigh-Durham airports.**  

![](img/plot-to-recreate.png)

**Extra Credit (5 pts)** - Create a visualization that effectively shows if there is a relationship between the average daily departure delay and the average daily temperature for all three New York city airports.
Your answer must be given in a single pipe.
(You should only spend time on this question once you have finished answering the others)